{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reviews\n",
    "train = pd.read_csv('data/IMDB_train.csv')\n",
    "test = pd.read_csv('data/IMDB_test.csv')\n",
    "valid = pd.read_csv('data/IMDB_dev.csv')\n",
    "\n",
    "#add review length to data framce\n",
    "#yelp['text length'] = yelp['text'].str.len()\n",
    "\n",
    "#sample for testing purppses\n",
    "#yelp = yelp.sample(frac=.5)\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['rating']\n",
    "\n",
    "X_test = test['text']\n",
    "y_test= test['rating']\n",
    "\n",
    "X_valid = valid['text']\n",
    "y_valid = valid['rating']\n",
    "\n",
    "X_full = X_train + X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 50000\n",
    "bow_transformer = CountVectorizer(max_features=max_vocab, binary=True, ngram_range=(1,3)).fit(X_full.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280593,)\n",
      "(34029,)\n",
      "(33793,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "\n",
    "X_train = bow_transformer.transform(X_train.values.astype('U'))\n",
    "X_valid = bow_transformer.transform(X_valid.values.astype('U'))\n",
    "X_test = bow_transformer.transform(X_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35599047870933614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import scipy.sparse as sp\n",
    "\n",
    "X_full = sp.vstack((X_train , X_valid))\n",
    "y_full = np.append(y_train, y_valid)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_full, y_full)\n",
    "y_hat = nb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type (y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314386,)\n",
      "(314386, 50000)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "def linSVM(parameters, X, T, fold) : \n",
    "    n_folds = 5\n",
    "    svc = LinearSVC(multi_class='ovr', dual=False)\n",
    "    svc_cv = GridSearchCV(svc, parameters, cv=fold, scoring=\"accuracy\", refit=False)\n",
    "    svc_cv.fit(X, T)\n",
    "    scores = svc_cv.cv_results_['mean_test_score']\n",
    "    params = svc_cv.cv_results_['params']\n",
    "    print('scores:',scores)\n",
    "    #print('params:',params)\n",
    "    return svc_cv.best_params_\n",
    "\n",
    "def SVM(parameters, X, T, fold) : \n",
    "    n_folds = 5\n",
    "    svmm = svm.SVC(kernel='linear')\n",
    "    svm_cv = GridSearchCV(svmm, parameters, cv=fold, scoring=\"accuracy\", refit=False)\n",
    "    svm_cv.fit(X, T)\n",
    "    scores = svm_cv.cv_results_['mean_test_score']\n",
    "    params = svm_cv.cv_results_['params']\n",
    "    print('scores:',scores)\n",
    "    print('params:',params)\n",
    "    return svm_cv.best_params_\n",
    "\n",
    "def MNB(parameters, X, T, fold) : \n",
    "    n_folds = 5\n",
    "    mnb = MultinomialNB(fit_prior=True)\n",
    "    mnb_cv = GridSearchCV(mnb, parameters, cv=fold, scoring=\"accuracy\", refit=False)\n",
    "    mnb_cv.fit(X, T)\n",
    "    scores = mnb_cv.cv_results_['mean_test_score']\n",
    "    params = mnb_cv.cv_results_['params']\n",
    "    print('scores:',scores)\n",
    "   #print('params:',params)\n",
    "    return mnb_cv.best_params_\n",
    "\n",
    "\n",
    "#Predefined Split for CV\n",
    "my_test_fold = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    my_test_fold.append(-1)\n",
    "for i in range(X_valid.shape[0]):\n",
    "    my_test_fold.append(0)\n",
    "\n",
    "fold = PredefinedSplit(test_fold=my_test_fold)\n",
    "CV_split_T = np.append(y_train, y_valid)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "CV_split_X = sp.vstack((X_train , X_valid))  # NOT np.vstack\n",
    "\n",
    "\n",
    "print(CV_split_T.shape)\n",
    "print(CV_split_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 123, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Cs = [ .0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "bestParams = linSVM(param_grid, CV_split_X, CV_split_T, fold)\n",
    "\n",
    "\n",
    "\n",
    "svc = LinearSVC(C=bestParams['C', multi_class='ovr', dual=False)       \n",
    "svc.fit(X_train, y_train)\n",
    "y_hat = svc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNB\n",
    "alphas = [ 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "\n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "bestParams = MNB(param_grid, CV_split_X, CV_split_T, fold)\n",
    "\n",
    "nb = MultinomialNB(alpha=bestParams['alpha'], fit_prior=True)\n",
    "nb.fit(X_train, y_train)\n",
    "y_hat = nb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_hat))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_hat))\n",
    "\n",
    "print(accuracy_score(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
